{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d705b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wikipediaapi\n",
    "import spacy\n",
    "\n",
    "df = pd.read_csv('data/companies.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c5ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose three companies for text processing:\n",
    "\n",
    "chosen_companies = df.loc[[1, 6, 7], 'company']\n",
    "\n",
    "print(chosen_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef861197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get company wikipedia information with WikipediaAPI\n",
    "wiki_wiki = wikipediaapi.Wikipedia('dk')\n",
    "\n",
    "company_wiki_texts = []\n",
    "\n",
    "for company in chosen_companies:\n",
    "    company_stripped = company.replace(\"A/S\", \"\")\n",
    "    wikipage = wiki_wiki.page(company_stripped)\n",
    "    company_wiki_texts.append(wikipage.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de7cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy text proccessing\n",
    "!conda -m spacy download da_core_news_sm\n",
    "\n",
    "# Load danish tokenizer\n",
    "nlp = spacy.load(\"da_core_news_sm\")\n",
    "\n",
    "# Create a spacy doc on the KMD wikipedia text\n",
    "doc = nlp(company_wiki_texts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tokens\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b72456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get verbs\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b29cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get nouns\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
